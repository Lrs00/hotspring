{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22d4d706-266d-4b7d-bcc7-006b6608a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from ppi_py import ppi_ols_ci\n",
    "from ppi_py import ppi_ols_pointestimate\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "527d3331-d52b-428f-9d98-eba293a1c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('cyanobacteria_thermotolerance_amino_acid_composition_wide.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d16d1c2d-6d48-4edd-a040-2adc9a811942",
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_acids = ['A', 'R', 'N','D','C','Q','E','G','H','I','L','K','M','F','P','S','T','W','Y','V']\n",
    "# Normalize by total AA count\n",
    "df['total_aa'] = df[amino_acids].sum(axis=1)\n",
    "for aa in amino_acids:\n",
    "    df[f'{aa}_freq'] = df[aa] / df['total_aa']\n",
    "\n",
    "high_quality_df = df[df['ogt'].notnull()].copy()\n",
    "low_quality_df = df[df['genome_type']=='single_cell'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f29c155-4a8f-439a-a24b-e6076e91998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop one amino acid (e.g., 'A')\n",
    "aa_freq_cols = [f'{aa}_freq' for aa in amino_acids if aa != 'A']\n",
    "\n",
    "X = high_quality_df[aa_freq_cols].values\n",
    "y = high_quality_df['ogt'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdfef1c-c75e-4363-b7d7-8c30cd08f0cc",
   "metadata": {},
   "source": [
    "## linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f469dc8b-9d98-4e48-8250-fa17c8719977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 2.043, RMSE: 2.782\n"
     ]
    }
   ],
   "source": [
    "loo = LeaveOneOut()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred.append(model.predict(X_test)[0])\n",
    "    y_true.append(y_test[0])\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "print(f\"MAE: {mae:.3f}, RMSE: {rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "326c7572-0251-4aa3-9bd3-7ebd26ef1d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.486, RMSE: 1.949\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Assume X is a DataFrame of amino acid frequencies (each row sums to 1)\n",
    "# and y is a continuous outcome\n",
    "\n",
    "def clr_transform(X):\n",
    "    # X: DataFrame or 2D numpy array with strictly positive values\n",
    "    X = np.asarray(X)\n",
    "    if np.any(X <= 0):\n",
    "        raise ValueError(\"CLR input must be strictly positive\")\n",
    "    log_X = np.log(X)\n",
    "    gm = np.mean(log_X, axis=1, keepdims=True)\n",
    "    return log_X - gm\n",
    "\n",
    "\n",
    "X_clr = clr_transform(X)  # Apply CLR transform\n",
    "\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "for train_idx, test_idx in loo.split(X_clr):\n",
    "    model.fit(X_clr[train_idx], y[train_idx])\n",
    "    pred = model.predict(X_clr[test_idx])[0]\n",
    "    y_true.append(y[test_idx][0])\n",
    "    y_pred.append(pred)\n",
    "    \n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "print(f\"MAE: {mae:.3f}, RMSE: {rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cb012f-e07d-45cc-b168-814056d1a8b2",
   "metadata": {},
   "source": [
    "## linear regression with PPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be6a5c7b-44c9-4de7-9206-4a46dc7a377f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPI:    MAE = 1209.84, RMSE = 1832.79\n",
      "Naive:  MAE = 3.01, RMSE = 4.33\n"
     ]
    }
   ],
   "source": [
    "n = len(y)\n",
    "y_true_all, y_pred_ppi_all, y_pred_naive_all = [], [], []\n",
    "\n",
    "for i in range(n):\n",
    "    # 1. Leave one out\n",
    "    X_test = X[i].reshape(1, -1)\n",
    "    y_test = y[i]\n",
    "    \n",
    "    X_train = np.delete(X, i, axis=0)\n",
    "    y_train = np.delete(y, i, axis=0)\n",
    "\n",
    "    # 2. Simulate PPI: randomly pick 10 as labeled\n",
    "    np.random.seed(i)  # for reproducibility\n",
    "    idx = np.random.permutation(len(X_train))\n",
    "    labeled_idx = idx[:10]\n",
    "    unlabeled_idx = idx[10:]\n",
    "\n",
    "    X_labeled = X_train[labeled_idx]\n",
    "    y_labeled = y_train[labeled_idx]\n",
    "    X_unlabeled = X_train[unlabeled_idx]\n",
    "    yhat_labeled = LinearRegression().fit(X_labeled, y_labeled).predict(X_labeled)\n",
    "    yhat_unlabeled = LinearRegression().fit(X_labeled, y_labeled).predict(X_unlabeled)\n",
    "\n",
    "    # 3. Apply PPI\n",
    "    ppi_beta = ppi_ols_pointestimate(X_labeled, y_labeled, yhat_labeled, X_unlabeled, yhat_unlabeled)\n",
    "    intercept = LinearRegression().fit(X_labeled, y_labeled).intercept_\n",
    "\n",
    "    # 4. Predict with PPI\n",
    "    y_pred_ppi = X_test @ ppi_beta + intercept\n",
    "\n",
    "    # 5. Predict with Naive\n",
    "    naive_model = LinearRegression().fit(X_labeled, y_labeled)\n",
    "    y_pred_naive = naive_model.predict(X_test)\n",
    "\n",
    "    # 6. Collect predictions\n",
    "    y_true_all.append(y_test)\n",
    "    y_pred_ppi_all.append(y_pred_ppi.item())\n",
    "    y_pred_naive_all.append(y_pred_naive.item())\n",
    "\n",
    "# 7. Report metrics\n",
    "mae_ppi = mean_absolute_error(y_true_all, y_pred_ppi_all)\n",
    "mae_naive = mean_absolute_error(y_true_all, y_pred_naive_all)\n",
    "rmse_ppi = mean_squared_error(y_true_all, y_pred_ppi_all, squared=False)\n",
    "rmse_naive = mean_squared_error(y_true_all, y_pred_naive_all, squared=False)\n",
    "\n",
    "print(f\"PPI:    MAE = {mae_ppi:.2f}, RMSE = {rmse_ppi:.2f}\")\n",
    "print(f\"Naive:  MAE = {mae_naive:.2f}, RMSE = {rmse_naive:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43d16c98-9637-47d7-bbea-98bbd09cd3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPI:    MAE = 558.26, RMSE = 814.82\n",
      "Naive:  MAE = 3.79, RMSE = 7.03\n"
     ]
    }
   ],
   "source": [
    "n = len(y)\n",
    "y_true_all, y_pred_ppi_all, y_pred_naive_all = [], [], []\n",
    "\n",
    "for i in range(n):\n",
    "    # 1. Leave one out\n",
    "    X_test = X_clr[i].reshape(1, -1)\n",
    "    y_test = y[i]\n",
    "    \n",
    "    X_train = np.delete(X_clr, i, axis=0)\n",
    "    y_train = np.delete(y, i, axis=0)\n",
    "\n",
    "    # 2. Simulate PPI: randomly pick 10 as labeled\n",
    "    np.random.seed(i)  # for reproducibility\n",
    "    idx = np.random.permutation(len(X_train))\n",
    "    labeled_idx = idx[:10]\n",
    "    unlabeled_idx = idx[10:]\n",
    "\n",
    "    X_labeled = X_train[labeled_idx]\n",
    "    y_labeled = y_train[labeled_idx]\n",
    "    X_unlabeled = X_train[unlabeled_idx]\n",
    "    yhat_labeled = LinearRegression().fit(X_labeled, y_labeled).predict(X_labeled)\n",
    "    yhat_unlabeled = LinearRegression().fit(X_labeled, y_labeled).predict(X_unlabeled)\n",
    "\n",
    "    # 3. Apply PPI\n",
    "    ppi_beta = ppi_ols_pointestimate(X_labeled, y_labeled, yhat_labeled, X_unlabeled, yhat_unlabeled)\n",
    "    intercept = LinearRegression().fit(X_labeled, y_labeled).intercept_\n",
    "\n",
    "    # 4. Predict with PPI\n",
    "    y_pred_ppi = X_test @ ppi_beta + intercept\n",
    "\n",
    "    # 5. Predict with Naive\n",
    "    naive_model = LinearRegression().fit(X_labeled, y_labeled)\n",
    "    y_pred_naive = naive_model.predict(X_test)\n",
    "\n",
    "    # 6. Collect predictions\n",
    "    y_true_all.append(y_test)\n",
    "    y_pred_ppi_all.append(y_pred_ppi.item())\n",
    "    y_pred_naive_all.append(y_pred_naive.item())\n",
    "\n",
    "# 7. Report metrics\n",
    "mae_ppi = mean_absolute_error(y_true_all, y_pred_ppi_all)\n",
    "mae_naive = mean_absolute_error(y_true_all, y_pred_naive_all)\n",
    "rmse_ppi = mean_squared_error(y_true_all, y_pred_ppi_all, squared=False)\n",
    "rmse_naive = mean_squared_error(y_true_all, y_pred_naive_all, squared=False)\n",
    "\n",
    "print(f\"PPI:    MAE = {mae_ppi:.2f}, RMSE = {rmse_ppi:.2f}\")\n",
    "print(f\"Naive:  MAE = {mae_naive:.2f}, RMSE = {rmse_naive:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808b5c04-3e53-41b8-8922-cd519085431c",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc86799e-ada5-4842-93fb-28dbce573f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest LOOCV → MAE: 1.21, RMSE: 1.69\n"
     ]
    }
   ],
   "source": [
    "loo = LeaveOneOut()\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)[0]\n",
    "\n",
    "    y_true_all.append(y_test[0])\n",
    "    y_pred_all.append(y_pred)\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_true_all, y_pred_all)\n",
    "rmse = mean_squared_error(y_true_all, y_pred_all, squared=False)\n",
    "\n",
    "print(f\"Random Forest LOOCV → MAE: {mae:.2f}, RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06adb4dd-44ac-470e-ad87-5021b6df9755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest LOOCV → MAE: 1.27, RMSE: 1.73\n"
     ]
    }
   ],
   "source": [
    "loo = LeaveOneOut()\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "X_clr = clr_transform(X)\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X_clr[train_index], X_clr[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)[0]\n",
    "\n",
    "    y_true_all.append(y_test[0])\n",
    "    y_pred_all.append(y_pred)\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_true_all, y_pred_all)\n",
    "rmse = mean_squared_error(y_true_all, y_pred_all, squared=False)\n",
    "\n",
    "print(f\"Random Forest LOOCV → MAE: {mae:.2f}, RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de396c3-47fd-486b-8e5f-9cb81a27fbe2",
   "metadata": {},
   "source": [
    "## boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5683ebd-de73-4e62-b558-801f49cd7c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost LOOCV - MAE: 1.32, RMSE: 1.85\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)[0]\n",
    "    \n",
    "    y_true_all.append(y_test[0])\n",
    "    y_pred_all.append(y_pred)\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_true_all, y_pred_all)\n",
    "rmse = mean_squared_error(y_true_all, y_pred_all, squared=False)\n",
    "\n",
    "print(f\"XGBoost LOOCV - MAE: {mae:.2f}, RMSE: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "413050f9-6c94-46fa-9bad-bd1405519219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost LOOCV - MAE: 1.49, RMSE: 1.95\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X_clr[train_index], X_clr[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)[0]\n",
    "    \n",
    "    y_true_all.append(y_test[0])\n",
    "    y_pred_all.append(y_pred)\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_true_all, y_pred_all)\n",
    "rmse = mean_squared_error(y_true_all, y_pred_all, squared=False)\n",
    "\n",
    "print(f\"XGBoost LOOCV - MAE: {mae:.2f}, RMSE: {rmse:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
